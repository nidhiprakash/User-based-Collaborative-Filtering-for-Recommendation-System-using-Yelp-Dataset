{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import shutil\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(sc, filepath, header=True):\n",
    "    \"\"\"Load data from a specified filepath. \n",
    "\n",
    "    If header is set to False,\n",
    "    the header will be removed from the first row of the RDD before being \n",
    "    returned.\n",
    "    \"\"\" \n",
    "    data = sc.textFile(filepath).map(lambda x: x.split(\",\"))\n",
    "    if not header:\n",
    "        hdr = data.first()\n",
    "        data = data.filter(lambda row: row != hdr)  # Remove header.\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize(rdd):\n",
    "    \"\"\"Factorize RDD column and return a mapping of {string: integer index}.\"\"\"\n",
    "    return rdd.distinct().sortBy(lambda x: x).zipWithIndex().collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_fn(value):\n",
    "    \"\"\"Bin predictions into one of five buckets.\"\"\"\n",
    "    if 0 <= value < 1:\n",
    "        return \">=0 and <1\"\n",
    "    elif 1 <= value < 2:\n",
    "        return \">=1 and <2\"\n",
    "    elif 2 <= value < 3:\n",
    "        return \">=2 and <3\"\n",
    "    elif 3 <= value < 4:\n",
    "        return \">=3 and <4\"\n",
    "    else:\n",
    "        return \">=4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_rating(rdd):\n",
    "    return (\n",
    "        rdd.aggregateByKey(tup, lambda a, b: (a[0] + b,    a[1] + 1),\n",
    "                             lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
    "        .mapValues(lambda v: v[0] / v[1])\n",
    "        .collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkContext.getOrCreate()\n",
    "sc.setCheckpointDir(\"checkpoint_dir/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFile = \"train_review.csv\"\n",
    "testFile = \"test_review.csv\"\n",
    "train = (load_data(sc, trainFile, header=False)\n",
    "            .map(lambda x: (x[0], x[1], int(x[2]))))\n",
    "test = (load_data(sc, testFile, header=False)\n",
    "            .map(lambda x: (x[0], x[1], int(x[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union train and test to get a combined feature mapping for all user and business IDs.\n",
    "combined = train.union(test)\n",
    "users = factorize(combined.map(itemgetter(0)))\n",
    "users_inv = {users[k]: k for k in users} \n",
    "businesses = factorize(combined.map(itemgetter(1)))\n",
    "businesses_inv = {businesses[k]: k for k in businesses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average user ratings as lookup/dictionary.\n",
    "tup = (0,0)\n",
    "avg_ratings = compute_mean_rating(train.map(lambda x: (x[0], float(x[-1]))))\n",
    "avg_ratings_item = compute_mean_rating(train.map(lambda x: (x[1], float(x[-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize ratings.\n",
    "train = train.map(lambda x: (x[0], x[1], x[2] - avg_ratings[x[0]]))\n",
    "\n",
    "# Get mapping of normalized ratings for each (user_id, business_id) pair.\n",
    "norm_ratings = train.map(lambda x: ((x[0], x[1]), x[2])).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sparse vectors for each user_id.\n",
    "sparse_vecs = (\n",
    "    train\n",
    "        # Normalize ratings be mean user ratings.\n",
    "        .map(lambda x: (users[x[0]], [(businesses[x[1]], x[-1] - avg_ratings[x[0]])]))\n",
    "        # \"Pivot\" data.\n",
    "        .reduceByKey(lambda x, y: x + y)\n",
    "        # Assemble sparse vectors for pearson correlation.\n",
    "        .map(lambda x: (x[0], Vectors.sparse(len(businesses), x[1])))\n",
    "        .collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate index of items mapping to users who rated that item. \n",
    "inv_index = (combined.map(lambda x: (x[1], [x[0]]))\n",
    "                .reduceByKey(lambda x, y: x + y)\n",
    "                .collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "weights = {}\n",
    "predictions = []\n",
    "for idx, (u, i, r) in enumerate(test.collect(), 1):\n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    sum_ = sum_w = 0\n",
    "    for u_ in inv_index[i]:\n",
    "        if (u, u_) in weights:\n",
    "            w = weights[(u, u_)]\n",
    "        else:\n",
    "            try:\n",
    "                x = sparse_vecs[users[u]]\n",
    "                y = sparse_vecs[users[u_]]\n",
    "\n",
    "                w = x.dot(y) / (x.norm(2) * y.norm(2))\n",
    "            except KeyError:\n",
    "                w = 0\n",
    "            weights[(u, u_)] = weights[(u_, u)] = w\n",
    "        sum_ += norm_ratings.get((u_, i), avg_ratings_item.get(i, 0) - avg_ratings.get(u, 0)) * w\n",
    "        sum_w += abs(w)\n",
    "\n",
    "    p = float(sum_) / (sum_w if sum_w else 1) + avg_ratings.get(u, 0)\n",
    "    p = p if p else avg_ratings_item.get(i, 2.5)\n",
    "    predictions.append(((u, i), p, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('YHWsLBS8jzZiPjKHMFOaAA', 'iKMLsX1Je7P3wAOEc9scDg'), 3.3499205756695196, 4), (('YHWsLBS8jzZiPjKHMFOaAA', 'amsvLzfEvCzLwP0MnXAJ1w'), 3.0827430052176625, 4), (('YHWsLBS8jzZiPjKHMFOaAA', '43PeF0ERpSIiEbXM6f9N2g'), 2.6579117451040983, 3), (('YHWsLBS8jzZiPjKHMFOaAA', 'y-sRypoTK2L6EuozhEMQzA'), 2.8174581229555473, 2), (('YHWsLBS8jzZiPjKHMFOaAA', 'VeVjZ8aR_zFEM9jKJuvraw'), 3.3414413782462304, 4)]\n"
     ]
    }
   ],
   "source": [
    "predictions = sc.parallelize(predictions)\n",
    "print(predictions.take(5))\n",
    "fname = 'Output'\n",
    "try:\n",
    "    shutil.rmtree(fname)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "(predictions\n",
    "    .map(lambda x: (x[0][0], x[0][1], x[1]))\n",
    "    .sortBy(lambda x: (x[0], x[1]))\n",
    "    .map(lambda x: ','.join(str(y) for y in x))\n",
    "    .coalesce(1)\n",
    "    .saveAsTextFile(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup output directory.\n",
    "shutil.move(next(glob.iglob('{}/part-00000'.format(fname))), fname + '.txt')\n",
    "shutil.rmtree(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins {'>=0 and <1': 31283, '>=1 and <2': 11163, '>=3 and <4': 381, '>=2 and <3': 2366, '>=4': 43}\n",
      "MSE 1.0426011246517954\n"
     ]
    }
   ],
   "source": [
    "# Join predictions with actual values and compute differences.\n",
    "diffs = predictions.map(lambda x: abs(x[1] - x[2]))\n",
    "\n",
    "# Partition diff values into 5 bins. \n",
    "bins = diffs.map(bin_fn).countByValue()\n",
    "\n",
    "# Compute Mean Squared Error.\n",
    "rmse = diffs.map(lambda x: x ** 2).mean() ** .5\n",
    "print(\"Bins\", dict(bins))\n",
    "print(\"MSE\", rmse)\n",
    "\n",
    "shutil.rmtree(\"checkpoint_dir/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
